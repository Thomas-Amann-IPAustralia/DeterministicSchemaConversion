# JSON Metadata Enrichment Logic

This document details the approach, logic, and architecture of the automated JSON enrichment workflow. The system is designed to programmatically identify missing data points (placeholders) within structured data files and replace them with high-quality, context-aware content generated by an Large Language Model (LLM).

## 1. Overview

The core objective of this system is to "repair" incomplete JSON datasets. It specifically targets fields marked with placeholder values (e.g., `xXx_PLACEHOLDER_xXx`) and resolves them into semantic values (e.g., specific step titles, SEO descriptions, or entity names) without altering the rest of the file structure.

The process is automated via GitHub Actions, ensuring consistent execution and reporting.

### High-Level Workflow

1. **Input:** A directory of JSON files (`json_output/`) containing placeholder strings.
2. **Process:** A Python script walks the JSON tree, identifies placeholders, generates prompts based on the surrounding context, and queries the OpenAI API.
3. **Validation:** A rigorous "Semantic Diff Check" ensures that *only* the targeted placeholders were modified.
4. **Output:** Enriched JSON files (`json_output-enriched/`) and a CSV audit log (`after_action_report.csv`).

---

## 2. Python Script Logic (`enrich_howto_steps.py`)

The script is the engine of this workflow. It operates on a "Safety First" principleâ€”it is better to fail a file than to corrupt it with hallucinated structure.

### A. Recursive Discovery

The script uses a recursive function (`recursive_enrich`) to traverse any depth of JSON nesting (dictionaries or lists). It looks for string values that match specific **Target Placeholders**:

* `xXx_PLACEHOLDER_xXx`
* `xXx_Err-PLACEHOLDER_xXx`

When a match is found, the script pauses traversal for that node and triggers the generation logic.

### B. Context-Aware Prompt Engineering

To generate accurate data, the script doesn't just ask for "a value." It analyzes the **Key** and the **Parent Object** to determine the specific *type* of data needed. This is handled in `generate_replacement_value`.

The script currently supports four distinct "Scenarios":

| Scenario | Trigger Condition | Logic / Prompt Strategy |
| --- | --- | --- |
| **1. HowToStep Name** | Key is `name`; Parent is `HowToStep` | **Input:** The `text` field of the step (instructions).<br>

<br>**Goal:** Generate a short, imperative title (e.g., "Fill out the form"). |
| **2. WebPage Description** | Key is `description` | **Input:** The document `headline` and a summary of `mainEntity` names.<br>

<br>**Goal:** Generate a concise SEO meta-description (max 160 chars). |
| **3. Organization Name** | Key is `name`; Parent has `url`/`alternateName` | **Input:** The `url` and `alternateName`.<br>

<br>**Goal:** Infer the proper official name of the provider or government body. |
| **4. Service Type** | Key is `serviceType` or `@type` | **Input:** The document `headline`.<br>

<br>**Goal:** Classify into Schema.org types (e.g., `GovernmentService`, `HowTo`). |
| **Fallback** | Any other key | **Input:** A string dump of the parent object.<br>

<br>**Goal:** Generic inference based on available context. |

### C. The "Semantic Diff Check" (Safety Mechanism)

A critical component of this script is `perform_diff_check`. After the LLM modifies the data, this function compares the *Original* file against the *Enriched* file to prevent "AI Hallucinations" or structural corruption.

It enforces the following strict rules:

1. **No Type Changes:** A string cannot become an object or list.
2. **No Structure Changes:** Keys cannot be added or removed.
3. **No Unintended Edits:** Values can *only* change if the original value was one of the defined `TARGET_PLACEHOLDERS`.

If the script detects that the LLM accidentally changed a valid field (e.g., changing a valid ID number while trying to fix a name), the file is flagged as **FAIL** in the report, alerting the maintainer to manual intervention.

---

## 3. Automation Architecture (`enrich_json_action.yml`)

The execution is wrapped in a GitHub Actions workflow to ensure reproducibility and ease of use.

### Triggers

* `workflow_dispatch`: The workflow is designed to be triggered manually. This allows the team to control when costs (API usage) are incurred and when changes are pushed.

### Job Steps

1. **Environment Setup:** Installs Python 3.10 and the `openai` library.
2. **Secure Execution:** Runs the script using `secrets.OPENAI_API_KEY` to authenticate with the LLM provider.
3. **Artifact Preservation:**
* **Enriched JSONs:** Uploaded as a zip artifact for inspection.
* **CSV Report:** Uploaded separately for quick auditing.


4. **Auto-Commit (Optional/Commented Out):** The workflow includes logic to automatically commit and push the enriched files back to the repository. This is currently disabled (commented out) to allow for a "Human-in-the-Loop" review process via artifacts first.

---

## 4. Reporting

The system generates an `after_action_report.csv` providing a granular audit trail. This is essential for QC (Quality Control).

**Report Columns:**

* **Service Name / UDID:** Identifies which record was touched.
* **Field Path:** The exact location of the change (e.g., `mainEntity[0].step[2].name`).
* **Original Placeholder:** What triggered the change.
* **Generated Value:** The content returned by the LLM.
* **Context Snippet:** The data sent to the LLM to generate the answer (useful for debugging prompt effectiveness).
* **Diff Check Results:** `Pass` or `Fail`.

---

## 5. Configuration Variables

The following variables in `enrich_howto_steps.py` control the process:

* `INPUT_DIR` / `OUTPUT_DIR`: Directory paths.
* `BATCH_SIZE`: Controls console logging grouping (default: 5 files per log group).
* `model`: Currently set to `gpt-4o` for high-reasoning capabilities on complex text interpretation.
* `temperature`: Set to `0.3` to ensure deterministic, focused outputs rather than "creative" writing.
